{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### groupby函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1、基本用法\n",
    "形式上，为DataFrame.groupby([variables])或Series.groupby([variables])，生成一个groupby类型的对象（分别叫DataFrameGroupBy和SeriesGroupBy），对这个对象可以再进行.mean()/.sum()/.count()的处理，类似于sas里对数据集进行group by的操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C\n",
      "0  a  1  4\n",
      "1  a  2  6\n",
      "2  b  3  5\n",
      "g = df.groupby(['A']):\n",
      "<pandas.core.groupby.groupby.DataFrameGroupBy object at 0x111ae2198>\n",
      "和apply联用后的结果\n",
      "          B    C\n",
      "0  0.333333  0.4\n",
      "1  0.666667  0.6\n",
      "2  1.000000  1.0\n"
     ]
    }
   ],
   "source": [
    "# 官方文档例子的理解\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'A': 'a a b'.split(), 'B': [1,2,3], 'C': [4,6, 5]})\n",
    "print(df)\n",
    "g = df.groupby(['A'])\n",
    "print(\"g = df.groupby(['A']):\")\n",
    "print(g)\n",
    "df_1 = g.apply(lambda x: x / x.sum())  # 和apply联用\n",
    "print('和apply联用后的结果')\n",
    "print(df_1)\n",
    "# 从结果上来看，g(DataFrame.groupby())在逻辑上仍然等同于DataFrame，只是有了groupby的信息（根据groupby信息分割的多个DataFrame）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.groupby.groupby.SeriesGroupBy object at 0x119894898>\n",
      "<pandas.core.groupby.groupby.SeriesGroupBy object at 0x119894358>\n",
      "<pandas.core.groupby.groupby.DataFrameGroupBy object at 0x1198944e0>\n",
      "<class 'pandas.core.series.Series'>\n",
      "MultiIndex(levels=[['California', 'Ohio'], [2005, 2006]],\n",
      "           labels=[[0, 0, 1, 1], [0, 1, 0, 1]])\n",
      "California  2005   -0.655099\n",
      "            2006   -0.249379\n",
      "Ohio        2005    1.942186\n",
      "            2006    0.426500\n",
      "Name: data1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 分组信息可以不来自于DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'key1':['a', 'a', 'b', 'b', 'a'],\n",
    "                            'key2':['one', 'two', 'one', 'two', 'one'],\n",
    "                            'data1':np.random.randn(5),\n",
    "                            'data2':np.random.randn(5)})\n",
    "\n",
    "states = np.array(['Ohio', 'California', 'California', 'Ohio', 'Ohio'])\n",
    "years = np.array([2005, 2005, 2006, 2005, 2006])\n",
    "g1 = df['data1'].groupby([states, years])  # 分组信息来自于其它数据（但是行数要对应上）\n",
    "g2 = df.groupby([states, years])['data1']  # 注意：这两种写法是等价的--也就是逻辑上等同于DataFrame的意思\n",
    "g3 = df.groupby([states, years])[['data1']]  # 注意：g3的类型和g1/g2不一样就很好理解了\n",
    "print(g1)\n",
    "print(g2)\n",
    "print(g3)\n",
    "df_1 = g1.mean()\n",
    "print(type(df_1))  # 注意：结果其实是一个Series，只是有一个MultiIndex\n",
    "print(df_1.index)\n",
    "print(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list(g1)的结果：\n",
      "[(('a', 'one'),   key1 key2     data1     data2\n",
      "0    a  one -0.718774  1.192843\n",
      "4    a  one -1.643126 -0.157505), (('a', 'two'),   key1 key2     data1     data2\n",
      "1    a  two  0.963136  1.117195), (('b', 'one'),   key1 key2     data1     data2\n",
      "2    b  one  0.059704  0.864151), (('b', 'two'),   key1 key2     data1     data2\n",
      "3    b  two -0.399036 -0.575472)]\n",
      "dict(g1_list)的结果：\n",
      "{('a', 'one'):   key1 key2     data1     data2\n",
      "0    a  one -0.718774  1.192843\n",
      "4    a  one -1.643126 -0.157505, ('a', 'two'):   key1 key2     data1     data2\n",
      "1    a  two  0.963136  1.117195, ('b', 'one'):   key1 key2     data1     data2\n",
      "2    b  one  0.059704  0.864151, ('b', 'two'):   key1 key2     data1     data2\n",
      "3    b  two -0.399036 -0.575472}\n",
      "将g1直接用在for循环里：\n",
      "a one\n",
      "  key1 key2     data1     data2\n",
      "0    a  one -0.718774  1.192843\n",
      "4    a  one -1.643126 -0.157505\n",
      "a two\n",
      "  key1 key2     data1     data2\n",
      "1    a  two  0.963136  1.117195\n",
      "b one\n",
      "  key1 key2     data1     data2\n",
      "2    b  one  0.059704  0.864151\n",
      "b two\n",
      "  key1 key2     data1     data2\n",
      "3    b  two -0.399036 -0.575472\n"
     ]
    }
   ],
   "source": [
    "# groupby的内容可以提取出来(和被分割的多个DataFrame的逻辑是一致的)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'key1':['a', 'a', 'b', 'b', 'a'],\n",
    "                            'key2':['one', 'two', 'one', 'two', 'one'],\n",
    "                            'data1':np.random.randn(5),\n",
    "                            'data2':np.random.randn(5)})\n",
    "\n",
    "g1 = df.groupby(['key1', 'key2'])\n",
    "\n",
    "g1_list = list(g1)  # 这个结果在spyder里面会更清晰一点，是一个list，每一list元素是一个元组(tuple)，而每一个元组又由一个复合index和一个DataFrame构成\n",
    "print('list(g1)的结果：')\n",
    "print(g1_list)\n",
    "g1_dict = dict(g1_list)\n",
    "print('dict(g1_list)的结果：')\n",
    "print(g1_dict)\n",
    "print('将g1直接用在for循环里：')\n",
    "for (k1, k2), group in g1:\n",
    "    print(k1, k2)\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2、用groupby()函数进行fama-macbeth回归\n",
    "fama-macbeth回归的思路，是先进行截面回归，再看截面回归系数的时序。在sas中可以用“proc reg; by date;”比较简单的完成，这里尝试用groupby()函数在python里也进行fama-macbeth回归。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  x1        x2\n",
      "2018-01-01  0.483233  1.255034\n",
      "2018-01-02  0.523127  1.087927\n",
      "2018-01-03  0.596617  1.145879\n",
      "2018-01-04  0.487350  1.145565\n",
      "2018-01-05  0.497071  1.057849\n",
      "2018-01-06  0.349764  1.190401\n",
      "2018-01-07  0.430165  1.216643\n",
      "2018-01-08  0.551273  1.219016\n",
      "2018-01-09  0.457809  1.062471\n",
      "2018-01-10  0.439193  1.096075\n",
      "2018-01-11  0.603069  1.283148\n",
      "2018-01-12  0.510601  1.322092\n",
      "2018-01-13  0.484822  1.239840\n",
      "2018-01-14  0.596872  1.115434\n",
      "2018-01-15  0.417653  1.149470\n",
      "2018-01-16  0.511738  1.170869\n",
      "2018-01-17  0.466286  1.146867\n",
      "2018-01-18  0.445645  1.192179\n",
      "2018-01-19  0.477549  1.233146\n",
      "2018-01-20  0.552809  1.452900\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 首先要做一个假数据，y=0.5*x1+1.2*x2，20个日期且每个日期20个数据（总共400个）\n",
    "\n",
    "day = 60 * 60 * 24\n",
    "\n",
    "start = time.mktime(time.strptime('2018-01-01', '%Y-%m-%d'))\n",
    "date = [i*day+start for i in range(20)]*20\n",
    "date = [time.strftime('%Y-%m-%d', time.localtime(i)) for i in date]\n",
    "date = np.array(date)\n",
    "x1 = np.array( list(4*np.random.randn(400)) )\n",
    "x2 = np.array( list(2*np.random.randn(400)) )\n",
    "y = 0.5*x1 + 1.2*x2 + np.array( list(np.random.randn(400)) )\n",
    "\n",
    "df = pd.DataFrame({'date': date, 'y': y, 'x1': x1, 'x2': x2})\n",
    "\n",
    "# 然后对每个时间截面进行线性回归，并将各个时点的结果保存在beta中，形成一个时序\n",
    "\n",
    "result = {}\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "\n",
    "for date, group in df.groupby('date'):\n",
    "    x_gp = group[['x1', 'x2']].values.reshape(-1, 2)\n",
    "    y_gp = group['y'].values.reshape(-1, 1)\n",
    "    model.fit(x_gp, y_gp)\n",
    "    b = model.coef_\n",
    "    result[date] = {'x1': b[0][0], 'x2': b[0][1]}\n",
    "\n",
    "beta = pd.DataFrame(result).T\n",
    "\n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
